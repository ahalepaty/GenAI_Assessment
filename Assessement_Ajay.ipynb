{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571d1d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.12/site-packages (2.9.0+cpu)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.16.3)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.19.1)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, pypdf2, hf-xet, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.2.0 huggingface-hub-0.36.0 pypdf2-3.0.1 regex-2025.11.3 safetensors-0.7.0 sentence-transformers-5.1.2 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "#STEP 1 — Install Dependencies\n",
    "!pip install pypdf2 sentence-transformers transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34707af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2 — Upload / Load the PDF\n",
    "file_path = \"/workspaces/GenAI_Assessment/NEP_Final_English_0.pdf\"  # << replace with your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c52e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300364,\n",
       " '1 \\n \\n \\nY  \\n \\n \\n \\n \\nNational  Education   \\nPolicy  2020  \\n \\n \\n \\nMinistry  of Human  \\nResource  Development  \\n \\nGovernment  of India  \\n \\n\\n1 \\n  \\nChapter   Contents  Page  \\nNo \\n Introduction  3 \\n PART   I.  SCHOOL  EDUCATION  \\n1  \\nEarly  Childhood  Care  and Education:  The Foundation  of Learning   7 \\n2 Foundational  Literacy  and Numeracy:  An Urgent  & Necessary  \\nPrerequisite  to Learning  8 \\n3 Curtailing  Dropout  Rates  and Ensuring  Universal  Access  to Education  at \\nAll Levels   10 \\n4 Curr')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 3 — Extract Text\n",
    "from PyPDF2 import PdfReader\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            full_text += text + \"\\n\"\n",
    "    return full_text\n",
    "document_text = extract_text_from_pdf(file_path)\n",
    "len(document_text), document_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a921b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 4 — Chunk the Text\n",
    "def chunk_text(text, chunk_size=1000, overlap=200):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "chunks = chunk_text(document_text)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e814cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "#STEP 5 — Load Models (Embedding + Generator)\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46bb7b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:31<00:00,  2.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([376, 384])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 6 — Create Embeddings for All Chunks\n",
    "chunk_embeddings = embedder.encode(chunks, convert_to_tensor=True, show_progress_bar=True)\n",
    "chunk_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d5298d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #STEP 7 — Retrieval Function\n",
    "import torch\n",
    "def retrieve_top_chunks(query, embeddings, chunks, model, top_k=3):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(query_embedding, embeddings)[0]\n",
    "    top_results = torch.topk(scores, k=top_k)\n",
    "    output = []\n",
    "    for idx, score in zip(top_results.indices.tolist(), top_results.values.tolist()):\n",
    "        output.append({\n",
    "            \"index\": idx,\n",
    "            \"score\": float(score),\n",
    "            \"text\": chunks[idx]\n",
    "        })\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d51142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 8 — Generate an Answer Using Retrieved Context (RAG)\n",
    "def answer_question(query, top_k=3):\n",
    "    retrieved = retrieve_top_chunks(query, chunk_embeddings, chunks, embedder, top_k)\n",
    "    context = \"\\n\\n\".join([f\"[source {r['index']}] {r['text'][:800]}\" for r in retrieved])\n",
    "    prompt = (\n",
    "        \"Use ONLY the following context to answer the question. \"\n",
    "        \"If answer not found, say 'not in document'.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    output = generator(prompt, max_length=250, do_sample=False)[0][\"generated_text\"]\n",
    "    return output, retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5a6080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=250) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER:\n",
      " a new conceptual perception/understanding for what constitutes a higher education institution (HEI), i.e., [source 190] pier, cohesive, cultured, productive, innovativ e, progressive, and prosperous nation\n",
      "\n",
      "SOURCES USED:\n",
      "Chunk 187 (score=0.757)\n",
      "Chunk 195 (score=0.742)\n",
      "Chunk 190 (score=0.739)\n"
     ]
    }
   ],
   "source": [
    "#STEP 9 — Ask a Question\n",
    "query = \"What are the New and Forward-looking Vision for India’s Higher Education System?\"\n",
    "answer, sources = answer_question(query)\n",
    "print(\"ANSWER:\\n\", answer)\n",
    "print(\"\\nSOURCES USED:\")\n",
    "for s in sources:\n",
    "    print(f\"Chunk {s['index']} (score={s['score']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1fec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=500) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National Education Policy 2020 Ministry of Human Resource Development Government of India 1 Chapter Contents Page No Introduction 3 PART I. SCHOOL EDUCATION 1 Early Childhood Care and Education: The Foundation of Learning 7 2 Foundational Literacy and Numeracy: An Urgent & Necessary Prerequisite to Learning 8 3 Curtailing Dropout Rates and Ensuring Universal Access to Education at All Levels 10 4 Curriculum and Pedagogy in Schools: Learning Should be Holistic, Integrated, Enjoyable and Engaging 11 5 Teachers 20 6 Equitable and Inclusive Educa 4tion: Learning for All 24 7 Efficient Resourcing and Effective Governance through School Complexes/Clusters 28 8 Standard -setting and Accreditation for School Education 30 PART II. HIGHER EDUCATION 9 Quality Universities and Colle ges: A New and Forward -looking Vision for India’s Higher Education System 33 10 Institutional Restructuring and Consolidation 34 11 Towards a More Holistic and Multidisciplinary Education 36 12 Optimal Learning Environments and Support for Students 38 13 Motivated, Energized and Capable Faculty 40 14 Equity and Inclusion in\n"
     ]
    }
   ],
   "source": [
    "#STEP 10 — Summarize Entire Document\n",
    "summary = generator(document_text[:8000], max_length=500, min_length=150, do_sample=False)\n",
    "print(summary[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
